{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe embeddings and LSTM model for predicting user rating of hotels based on the review text\n",
    "The dataset was provided by HSE \"Intro to Deep Learning\" [course](http://wiki.cs.hse.ru/Основы_глубинного_обучения).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T10:38:20.680380Z",
     "iopub.status.busy": "2022-04-13T10:38:20.680060Z",
     "iopub.status.idle": "2022-04-13T10:38:24.585313Z",
     "shell.execute_reply": "2022-04-13T10:38:24.584590Z",
     "shell.execute_reply.started": "2022-04-13T10:38:20.680311Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imports and setting up wandb\n",
    "\n",
    "import torch \n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import wandb \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchtext.legacy import data\n",
    "from torchtext.legacy import datasets\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "TRAIN_PATH = '../input/hotelreviews/train.csv'\n",
    "\n",
    "wandb.login(key='XXX') #placeholder key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train dataset consists of 100.000 reviews, each review consists of two separate parts: positive feedback and negative feedback. The rating is provided in the `score` column - a real number in range of 0-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T10:38:24.587540Z",
     "iopub.status.busy": "2022-04-13T10:38:24.587267Z",
     "iopub.status.idle": "2022-04-13T10:38:25.146870Z",
     "shell.execute_reply": "2022-04-13T10:38:25.146139Z",
     "shell.execute_reply.started": "2022-04-13T10:38:24.587503Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There were issues with the wifi connection</td>\n",
       "      <td>No Positive</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TV not working</td>\n",
       "      <td>No Positive</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>More pillows</td>\n",
       "      <td>Beautiful room Great location Lovely staff</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very business</td>\n",
       "      <td>Location</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rooms could do with a bit of a refurbishment ...</td>\n",
       "      <td>Nice breakfast handy for Victoria train stati...</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hotel is under reconstruction and should be c...</td>\n",
       "      <td>Location is excellent for congress activities</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Noise from the trains and road but ok for one...</td>\n",
       "      <td>Great location to tube station and local shop...</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>No Negative</td>\n",
       "      <td>Great location friendly staff and lovely acco...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I known you re renovating but having concierg...</td>\n",
       "      <td>Staff were super helpful and friendly Great l...</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Location of room no phone signal</td>\n",
       "      <td>friendly staff</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            negative  \\\n",
       "0         There were issues with the wifi connection   \n",
       "1                                     TV not working   \n",
       "2                                       More pillows   \n",
       "3                                      Very business   \n",
       "4   Rooms could do with a bit of a refurbishment ...   \n",
       "5   Hotel is under reconstruction and should be c...   \n",
       "6   Noise from the trains and road but ok for one...   \n",
       "7                                        No Negative   \n",
       "8   I known you re renovating but having concierg...   \n",
       "9                   Location of room no phone signal   \n",
       "\n",
       "                                            positive  score  \n",
       "0                                        No Positive    7.1  \n",
       "1                                        No Positive    7.5  \n",
       "2        Beautiful room Great location Lovely staff    10.0  \n",
       "3                                           Location    5.4  \n",
       "4   Nice breakfast handy for Victoria train stati...    6.7  \n",
       "5     Location is excellent for congress activities     6.3  \n",
       "6   Great location to tube station and local shop...    8.8  \n",
       "7   Great location friendly staff and lovely acco...   10.0  \n",
       "8   Staff were super helpful and friendly Great l...    9.2  \n",
       "9                                     friendly staff    6.7  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv(TRAIN_PATH).drop(['review_id'], axis=1)\n",
    "reviews.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T10:38:25.148568Z",
     "iopub.status.busy": "2022-04-13T10:38:25.148175Z",
     "iopub.status.idle": "2022-04-13T10:38:25.154469Z",
     "shell.execute_reply": "2022-04-13T10:38:25.153775Z",
     "shell.execute_reply.started": "2022-04-13T10:38:25.148531Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_all(seed_value): #function to fix random seed\n",
    "    random.seed(seed_value) \n",
    "    np.random.seed(seed_value) \n",
    "    torch.manual_seed(seed_value) \n",
    "    if torch.cuda.is_available() :\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) \n",
    "        torch.backends.cudnn.deterministic = True \n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do a bit of data cleansing, such as removing some bad symbols and converting text to lowercase. This dataset does not have punctuation included, so we don't have to worry about handling that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T10:38:25.156801Z",
     "iopub.status.busy": "2022-04-13T10:38:25.156484Z",
     "iopub.status.idle": "2022-04-13T10:38:25.164172Z",
     "shell.execute_reply": "2022-04-13T10:38:25.163240Z",
     "shell.execute_reply.started": "2022-04-13T10:38:25.156767Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text) #non-ASCII\n",
    "    text = re.sub('[\\\\r\\\\t\\\\n]+', ' ', text) #delimiters\n",
    "    return ' '.join(text.lower().split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work with one text we will concatenate both parts of the review with a special separator token `SEP` in between. Approach with two separate `LSTM` models for positive and negative feedbacks was tried as well but showed worse results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T10:38:25.166174Z",
     "iopub.status.busy": "2022-04-13T10:38:25.165559Z",
     "iopub.status.idle": "2022-04-13T10:38:28.564041Z",
     "shell.execute_reply": "2022-04-13T10:38:28.563289Z",
     "shell.execute_reply.started": "2022-04-13T10:38:25.166138Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_train_data():\n",
    "    df = pd.read_csv(TRAIN_PATH).drop(['review_id'], axis=1)    \n",
    "    df['review'] = df.negative + ' SEP ' + df.positive\n",
    "    df.review = df.review.apply(lambda x: clean_text(x))\n",
    "    df.to_csv('train_merged.csv', index=False, columns=['review', 'score'])\n",
    "    \n",
    "get_train_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting up `torchtext` `Field` structures to define how we will process the data.**\n",
    "\n",
    "We'll be using built in `spaCy` tokenizer, also we will include information about lengths of texts by specifying `include_lengths=True`. This will be useful later during batching and padding steps.  \n",
    "\n",
    "For the `RATING` field we will not be using a vocabulary since it's a real number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T10:38:28.565371Z",
     "iopub.status.busy": "2022-04-13T10:38:28.565139Z",
     "iopub.status.idle": "2022-04-13T10:38:37.900623Z",
     "shell.execute_reply": "2022-04-13T10:38:37.899881Z",
     "shell.execute_reply.started": "2022-04-13T10:38:28.565341Z"
    }
   },
   "outputs": [],
   "source": [
    "REVIEW = data.Field(\n",
    "    tokenize='spacy', \n",
    "    tokenizer_language='en_core_web_sm', \n",
    "    include_lengths=True,\n",
    "    batch_first=True\n",
    ")\n",
    "\n",
    "RATING = data.LabelField(\n",
    "    dtype=torch.float, \n",
    "    use_vocab=False, \n",
    "    preprocessing=float, \n",
    "    batch_first=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating train instance of `TabularDataset` and splitting to train and validation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T10:38:37.902369Z",
     "iopub.status.busy": "2022-04-13T10:38:37.902137Z",
     "iopub.status.idle": "2022-04-13T10:38:49.703821Z",
     "shell.execute_reply": "2022-04-13T10:38:49.703099Z",
     "shell.execute_reply.started": "2022-04-13T10:38:37.902337Z"
    }
   },
   "outputs": [],
   "source": [
    "train_fields = [('review', REVIEW), ('rating', RATING)]\n",
    "\n",
    "train_data = data.TabularDataset(\n",
    "    path='./train_merged.csv',\n",
    "    format='csv',\n",
    "    fields=train_fields,\n",
    "    skip_header=True\n",
    ")\n",
    "\n",
    "train_data, valid_data = train_data.split(random_state = random.seed(21))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T12:52:29.338706Z",
     "iopub.status.busy": "2022-04-10T12:52:29.338409Z",
     "iopub.status.idle": "2022-04-10T12:52:29.344965Z",
     "shell.execute_reply": "2022-04-10T12:52:29.343829Z",
     "shell.execute_reply.started": "2022-04-10T12:52:29.338672Z"
    }
   },
   "source": [
    "**Building vocabulary of the `REVIEW` field.**\n",
    "\n",
    "Instead of training our own word embeddings, we'll be using pretrained `GloVe` embeddings. Different types of embeddings and dimensions were tested, using `GloVe` embeddings with dimension of `200` showed the best results. Vectors for words which are not present in `GloVe` vocabulary will be initialized from standard normal distribution by specifying `unk_init=torch.Tensor.normal_`.  \n",
    "\n",
    "We will ll also limit our vocabulary only to tokens which are present in at least three different reviews by setting `min_freq` parameter to 3. This is done to reduce vocabulary size and avoid overfitting .  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T10:38:49.705216Z",
     "iopub.status.busy": "2022-04-13T10:38:49.704965Z",
     "iopub.status.idle": "2022-04-13T10:42:22.927796Z",
     "shell.execute_reply": "2022-04-13T10:42:22.927003Z",
     "shell.execute_reply.started": "2022-04-13T10:38:49.705183Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [02:40, 5.36MB/s]                               \n",
      "100%|█████████▉| 399999/400000 [00:31<00:00, 12585.64it/s]\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 200\n",
    "\n",
    "REVIEW.build_vocab(\n",
    "    train_data, \n",
    "    min_freq=3, \n",
    "    unk_init=torch.Tensor.normal_,\n",
    "    vectors = 'glove.6B.' + str(EMBEDDING_DIM) + 'd',\n",
    ")\n",
    "\n",
    "VOCAB_SIZE = len(REVIEW.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating train and test iterators.**\n",
    "\n",
    "We'll be using a `BucketIterator` - a special type of iterator that will return a batch of instances, where each instance is of a similar length, minimizing the amount of padding per instance.  \n",
    "\n",
    "`sort_within_batch` parameter is specified to sort instances within batch. This is necessary in order to use `nn.utils.rnn.packed_padded_sequence` later to pack a sequence in a way that only the non-padded elements will be processed by the `LSTM` model. We'll need to define the `sort_key` parameter - how we want to sort instaces within batch, in this case it's by the length of the review text. Since the text has been already tokenized, we can just use `len` of the instance.   \n",
    "\n",
    "Since we don't backpropagate during validation loop we can set larger batch size of 256 for the validation iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T10:42:22.929519Z",
     "iopub.status.busy": "2022-04-13T10:42:22.929272Z",
     "iopub.status.idle": "2022-04-13T10:42:22.934280Z",
     "shell.execute_reply": "2022-04-13T10:42:22.933631Z",
     "shell.execute_reply.started": "2022-04-13T10:42:22.929486Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZES = (8, 256)\n",
    "\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data),\n",
    "    sort_within_batch=True,\n",
    "    sort_key = lambda x: len(x.review), \n",
    "    batch_sizes=BATCH_SIZES,\n",
    "    device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll set the embeddings for `PAD` and `UNK` tokens used for padding and unknown words respectively to zero vectors to explicitly tell our model that they are irrelevant for determining a score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T10:42:22.937527Z",
     "iopub.status.busy": "2022-04-13T10:42:22.937036Z",
     "iopub.status.idle": "2022-04-13T10:42:22.944579Z",
     "shell.execute_reply": "2022-04-13T10:42:22.943886Z",
     "shell.execute_reply.started": "2022-04-13T10:42:22.937490Z"
    }
   },
   "outputs": [],
   "source": [
    "PAD_IDX = REVIEW.vocab.stoi[REVIEW.pad_token]\n",
    "UNK_IDX = REVIEW.vocab.stoi[REVIEW.unk_token]\n",
    "\n",
    "pretrained_embeddings = REVIEW.vocab.vectors\n",
    "\n",
    "pretrained_embeddings[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "pretrained_embeddings[UNK_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining the model.**\n",
    "\n",
    "We'll be using a bidirecitonal `LSTM` model.  \n",
    "\n",
    "First, `nn.Embedding` layer, which is a simple word-embedding look-up table, will process the input sequence. We provide the `pretrained_embeddings` tensor to this layer with pretrained embeddings information we set up earlier. Also we specify `freeze` parameter as `False`, allowing the embeddings to be changed during backpropagating process. After that, `nn.Dropout` is applied to control overfitting.  \n",
    "\n",
    "Next, we pack our input with `nn.utils.rnn.pack_padded_sequence` in order to efficiently process the input sequence with `LSTM` model and feed packed input to the model.\n",
    "\n",
    "The model itself will return three tensors:\n",
    "* `output` - a tensor containing all hidden states at every time step\n",
    "* `h_n` - a tensor containing the final hidden state\n",
    "* `c_n` - a tensor containing the final cell state  \n",
    "\n",
    "We expect that the last hidden state contains encoded information about the whole input sequence. Since we are using bidirectional `LSTM` we concatenate results from both directions and pass it to the `nn.Linear` layer for the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T10:42:22.946670Z",
     "iopub.status.busy": "2022-04-13T10:42:22.946115Z",
     "iopub.status.idle": "2022-04-13T10:42:22.956710Z",
     "shell.execute_reply": "2022-04-13T10:42:22.955718Z",
     "shell.execute_reply.started": "2022-04-13T10:42:22.946631Z"
    }
   },
   "outputs": [],
   "source": [
    "class LSTM(torch.nn.Module) :\n",
    "    def __init__(self, pretrained_embeddings, embedding_dim, padding_idx,\n",
    "                 hidden_dim, num_layers=1, bidirectional=True, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embeddings = nn.Embedding.from_pretrained(pretrained_embeddings, \n",
    "                                                       padding_idx=padding_idx, \n",
    "                                                       freeze=False)\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, \n",
    "                            batch_first=True, \n",
    "                            bidirectional=bidirectional, \n",
    "                            num_layers=num_layers)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.linear = nn.Linear(hidden_dim * 2, 1)\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        embedded = self.embeddings(text)\n",
    "        embedded = self.dropout(embedded)\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, \n",
    "                                                            text_lengths.to('cpu'), \n",
    "                                                            batch_first=True)\n",
    "        lstm_out, (hst, cst) = self.lstm(packed_embedded)\n",
    "        hidden = torch.cat([hst[-2, :, :], hst[-1, :, :]], dim=1)\n",
    "        return self.linear(hidden).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining the model and moving it to GPU if available.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T10:42:22.961018Z",
     "iopub.status.busy": "2022-04-13T10:42:22.957671Z",
     "iopub.status.idle": "2022-04-13T10:42:30.685437Z",
     "shell.execute_reply": "2022-04-13T10:42:30.684711Z",
     "shell.execute_reply.started": "2022-04-13T10:42:22.960979Z"
    }
   },
   "outputs": [],
   "source": [
    "seed_all(21)\n",
    "\n",
    "HIDDEN_DIM = 300\n",
    "NUM_LAYERS = 3\n",
    "DROPOUT = 0.3\n",
    "BIDIRECTIONAL = True\n",
    "        \n",
    "lstm = LSTM(\n",
    "    pretrained_embeddings = pretrained_embeddings,\n",
    "    embedding_dim = EMBEDDING_DIM,\n",
    "    padding_idx = PAD_IDX,\n",
    "    hidden_dim = HIDDEN_DIM,\n",
    "    num_layers = NUM_LAYERS,\n",
    "    bidirectional = BIDIRECTIONAL,\n",
    "    dropout = DROPOUT\n",
    ")\n",
    "\n",
    "lstm = lstm.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining learning rate, optimizer, scheduler and loss function.**   \n",
    "\n",
    "We'll be using MAE loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T10:42:30.687194Z",
     "iopub.status.busy": "2022-04-13T10:42:30.686911Z",
     "iopub.status.idle": "2022-04-13T10:42:30.694765Z",
     "shell.execute_reply": "2022-04-13T10:42:30.694005Z",
     "shell.execute_reply.started": "2022-04-13T10:42:30.687160Z"
    }
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 3e-4\n",
    "LOSS_NAME = 'MAE'\n",
    "\n",
    "optimizer = torch.optim.AdamW(lstm.parameters(), lr = LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.98)\n",
    "criterion = F.l1_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining the train loop.**\n",
    "\n",
    "`predict` function will return three tensors:  \n",
    "* `losses` tensor with the loss value for every element of iterator  \n",
    "* `predicted_ratings` tensor with the model predictions  \n",
    "* `true_ratings` tensor with the actual ratings\n",
    "\n",
    "We'll also be [exporting](https://wandb.ai/porfiry/hotels-reviews?workspace=user-porfiry) the results to `wandb` to easily track and visualise the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T10:42:30.698317Z",
     "iopub.status.busy": "2022-04-13T10:42:30.698082Z",
     "iopub.status.idle": "2022-04-13T10:42:30.715697Z",
     "shell.execute_reply": "2022-04-13T10:42:30.714724Z",
     "shell.execute_reply.started": "2022-04-13T10:42:30.698291Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_iterator, criterion, optimizer, scheduler=None):\n",
    "    model.train()\n",
    "    for reviews, ratings in tqdm(train_iterator):\n",
    "        reviews, reviews_lengths = reviews[0], reviews[1]\n",
    "        reviews, reviews_lengths, ratings = reviews.to(DEVICE), reviews_lengths.to(DEVICE), ratings.to(DEVICE)\n",
    "        predictions = model(reviews, reviews_lengths)\n",
    "        loss = criterion(predictions, ratings)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if scheduler != None:\n",
    "        scheduler.step()\n",
    "\n",
    "def predict(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    predicted_ratings = torch.tensor([], device=DEVICE)\n",
    "    true_ratings = torch.tensor([], device=DEVICE)\n",
    "    losses = torch.tensor([], device=DEVICE)\n",
    "    with torch.no_grad():\n",
    "        for reviews, ratings in tqdm(iterator):\n",
    "            reviews, reviews_lengths = reviews[0], reviews[1]\n",
    "            reviews, reviews_lengths, ratings = reviews.to(DEVICE), reviews_lengths.to(DEVICE), ratings.to(DEVICE)\n",
    "            batch_predictions = model(reviews, reviews_lengths)\n",
    "            predicted_ratings = torch.cat([predicted_ratings, batch_predictions])\n",
    "            true_ratings = torch.cat([true_ratings, ratings])\n",
    "            batch_losses = criterion(batch_predictions, ratings, reduction='none')\n",
    "            losses = torch.cat([losses, batch_losses])\n",
    "    return losses, predicted_ratings, true_ratings\n",
    "\n",
    "def train(model, train_iterator, criterion, optimizer, n_epochs=10, \n",
    "          val_iterator=None, scheduler=None, project=None, resume=False, params=None):\n",
    "    \n",
    "    # resume is a flag to continue the same wandb run in case we want to continue training\n",
    "    # the model after initial train loop\n",
    "    if resume:\n",
    "        wandb.init(project=project, resume='must', id=wandb.run.id, config=params)\n",
    "    else:\n",
    "        wandb.init(project=project, config=params)\n",
    "        \n",
    "    wandb.watch(model)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        train_one_epoch(model, train_iterator, criterion, optimizer, scheduler)\n",
    "        if val_iterator != None:\n",
    "            val_loss, val_preds, val_ratings = predict(model, val_iterator, criterion)\n",
    "            print(f'Epoch: {epoch+1}, validation {LOSS_NAME}: {val_loss.mean()}')\n",
    "        train_loss, train_preds, train_ratings = predict(model, train_iterator, criterion)\n",
    "        print(f'Epoch: {epoch+1}, train {LOSS_NAME}: {train_loss.mean()}')\n",
    "        \n",
    "        # logging has to be done separately because we can't keep track of steps for wandb\n",
    "        # in case of continuing training after initial train loop\n",
    "        if val_iterator != None:\n",
    "            wandb.log({\n",
    "              f'mean train {LOSS_NAME}': train_loss.mean(),\n",
    "              f'mean val {LOSS_NAME}': val_loss.mean()\n",
    "              }) \n",
    "        else:\n",
    "            wandb.log({\n",
    "              f'mean train {LOSS_NAME}': train_loss.mean()\n",
    "              }) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beginning training.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T10:42:30.717696Z",
     "iopub.status.busy": "2022-04-13T10:42:30.717211Z",
     "iopub.status.idle": "2022-04-13T11:12:05.726132Z",
     "shell.execute_reply": "2022-04-13T11:12:05.724965Z",
     "shell.execute_reply.started": "2022-04-13T10:42:30.717599Z"
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "RESUME PREVIOUS RUN?  no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming previous run: False\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "N EPOCHS?  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mporfiry\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 10 epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.14 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20220413_104240-2bir0y9k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/porfiry/hotel-reviews/runs/2bir0y9k\" target=\"_blank\">young-pond-166</a></strong> to <a href=\"https://wandb.ai/porfiry/hotel-reviews\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8750/8750 [02:14<00:00, 64.98it/s]\n",
      "100%|██████████| 118/118 [00:02<00:00, 40.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, validation MAE: 0.8558124899864197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8750/8750 [00:40<00:00, 217.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, train MAE: 0.8344889283180237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8750/8750 [02:12<00:00, 65.84it/s]\n",
      "100%|██████████| 118/118 [00:02<00:00, 42.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, validation MAE: 0.7614631652832031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8750/8750 [00:40<00:00, 217.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, train MAE: 0.7184240221977234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8750/8750 [02:12<00:00, 65.98it/s]\n",
      "100%|██████████| 118/118 [00:02<00:00, 41.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, validation MAE: 0.7579575181007385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8750/8750 [00:39<00:00, 219.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, train MAE: 0.6949464082717896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8750/8750 [02:12<00:00, 65.87it/s]\n",
      "100%|██████████| 118/118 [00:02<00:00, 41.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, validation MAE: 0.7493607401847839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8750/8750 [00:40<00:00, 217.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, train MAE: 0.6655190587043762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8750/8750 [02:12<00:00, 66.02it/s]\n",
      "100%|██████████| 118/118 [00:02<00:00, 39.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, validation MAE: 0.7399376630783081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8750/8750 [00:39<00:00, 218.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, train MAE: 0.6349638104438782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8750/8750 [02:12<00:00, 66.14it/s]\n",
      "100%|██████████| 118/118 [00:02<00:00, 41.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, validation MAE: 0.7475746273994446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8750/8750 [00:39<00:00, 219.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, train MAE: 0.6125217080116272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8750/8750 [02:12<00:00, 66.07it/s]\n",
      "100%|██████████| 118/118 [00:02<00:00, 42.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, validation MAE: 0.7524238228797913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8750/8750 [00:40<00:00, 218.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, train MAE: 0.6039032340049744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8750/8750 [02:12<00:00, 65.84it/s]\n",
      "100%|██████████| 118/118 [00:02<00:00, 42.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, validation MAE: 0.755949854850769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8750/8750 [00:40<00:00, 218.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, train MAE: 0.5822247266769409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8750/8750 [02:12<00:00, 65.91it/s]\n",
      "100%|██████████| 118/118 [00:02<00:00, 40.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, validation MAE: 0.7548894882202148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8750/8750 [00:40<00:00, 217.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, train MAE: 0.5589897036552429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8750/8750 [02:12<00:00, 65.88it/s]\n",
      "100%|██████████| 118/118 [00:02<00:00, 41.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, validation MAE: 0.7504647374153137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8750/8750 [00:40<00:00, 216.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, train MAE: 0.5262979865074158\n"
     ]
    }
   ],
   "source": [
    "def log_params(): #log model and training parameters to wandb\n",
    "    params = {}\n",
    "    params['bidirectional'] = BIDIRECTIONAL\n",
    "    params['num layers'] = NUM_LAYERS\n",
    "    params['hidden dim'] = HIDDEN_DIM\n",
    "    params['embedding dim'] = EMBEDDING_DIM\n",
    "    params['dropout'] = DROPOUT\n",
    "    params['vocab size'] = VOCAB_SIZE\n",
    "    params['learning rate'] = LEARNING_RATE\n",
    "    params['train batch size'] = BATCH_SIZES[0]\n",
    "    params['model'] = lstm\n",
    "    params['optimizer'] = optimizer\n",
    "    params['scheduler'] = scheduler\n",
    "    return params\n",
    "\n",
    "def start_training(params):\n",
    "    resume = True if (str.lower(input('RESUME PREVIOUS RUN? ')) == 'y') else False\n",
    "    print('Resuming previous run:', resume)\n",
    "    \n",
    "    n_epochs = int(input('N EPOCHS? '))\n",
    "    print('Training', n_epochs, 'epochs', end='\\n')\n",
    "\n",
    "    train(lstm, \n",
    "          train_iterator, \n",
    "          criterion, \n",
    "          optimizer, \n",
    "          n_epochs=n_epochs, \n",
    "          val_iterator=valid_iterator, \n",
    "          scheduler=scheduler, \n",
    "          project='hotels-reviews', \n",
    "          resume=resume, \n",
    "          params=params)\n",
    "    \n",
    "params = log_params()\n",
    "start_training(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different architectures and sets of hyperparameters were tested. The model was able to [achieve](https://wandb.ai/porfiry/hotels-reviews?workspace=user-porfiry) on average 0.75 MAE on validation and 0.55 MAE on train on this train-validation split."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
